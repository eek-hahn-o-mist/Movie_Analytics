{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from re import sub\n",
    "import time\n",
    "import random\n",
    "from faker import Factory\n",
    "from easymoney.money import EasyPeasy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use data from the numbers website to get movie title, budget numbers, box office numbers and worldwide numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get base URL and parse XTML of that URL\n",
    "gross_base_URL = 'http://www.the-numbers.com/movie/budgets/all'\n",
    "gross_r = requests.get('http://www.the-numbers.com/movie/budgets/all')\n",
    "movie_num = BeautifulSoup(gross_r.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get numbers and movie name html childs\n",
    "movie_num_tr = movie_num.find_all('td',class_='data')\n",
    "movie_num_names = movie_num.find_all('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get all movie names\n",
    "movie_names = ([td.get_text().replace('Ã¢\\x80\\x99',\"'\") for td in movie_num_names[1:]])\n",
    "\n",
    "#Encode movies to get the proper text\n",
    "for mov in range(0,len(movie_names)):\n",
    "    movie_names[mov] = movie_names[mov].encode('ascii',\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get budget, domestic and worldwide information\n",
    "budget = []\n",
    "domestic = []\n",
    "worldwide = []\n",
    "rego = 4\n",
    "\n",
    "for tr in movie_num_tr:\n",
    "    if rego ==0:\n",
    "        rego = 4\n",
    "    rego -=1\n",
    "    num = int(re.sub(\"[^0-9|.]\",\"\",tr.get_text()))\n",
    "    if rego ==2:\n",
    "        budget.append(num)\n",
    "    if rego ==1:\n",
    "        domestic.append(num)\n",
    "    if rego ==0:\n",
    "        worldwide.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Remove those items that aren't movies\n",
    "del movie_names[len(movie_names)-(len(movie_names) - len(budget)):len(movie_names)]\n",
    "\n",
    "#Add a movie ID list\n",
    "movie_id.extend(range(0,len(movie_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go to the IMDB website and get the unique urls for each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get base URL for IMDB search\n",
    "imdb_base = 'http://www.imdb.com/find?ref_=nv_sr_fn&q={0}&s=all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loop through the movie names to get the unique URLs for each movie\n",
    "imdb_url = []\n",
    "movies_dict ={}\n",
    "count = 0\n",
    "for movie in movie_names:\n",
    "    imdb_search = requests.get(imdb_base.format(movie))\n",
    "    imdb_soup = BeautifulSoup(imdb_search.text,'lxml')\n",
    "    try:\n",
    "        if('name' in imdb_soup.find('td', class_='result_text').a['href']) or ('company' in imdb_soup.find('td', class_='result_text')) or ('Video' in imdb_soup.find('td', class_='result_text').text) or ('TV' in imdb_soup.find('td', class_='result_text').text):\n",
    "            if 'and' in movie.decode():\n",
    "                imdb_search = requests.get(imdb_base.format(movie.decode().replace('and','')))\n",
    "                imdb_soup = BeautifulSoup(imdb_search.text,'lxml')\n",
    "                imdb_url.append(imdb_soup.find('td',class_='result_text').a['href'])\n",
    "            else:\n",
    "                imdb_url.append(None)\n",
    "        else:\n",
    "            imdb_url.append(imdb_soup.find('td',class_='result_text').a['href'])\n",
    "    except AttributeError:\n",
    "        imdb_url.append(None)\n",
    "    movies_dict[movie]=imdb_url[count]\n",
    "    count += 1\n",
    "    time.sleep(random.uniform(.02,5)) #put breaks into the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get base for IMDB website\n",
    "fake = Factory.create()\n",
    "header = {'User-Agent':fake.chrome()}\n",
    "imdb_page_base = 'http://www.imdb.com{0}'\n",
    "imdb_page = requests.get(imdb_page_base.format(imdb_url[10]),headers = header)\n",
    "imdb_p_soup = BeautifulSoup(imdb_page.text,'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loop through each URL to get specific data about each movie\n",
    "imdb_rating = []\n",
    "imdb_num_rating=[]\n",
    "genres = []\n",
    "director = []\n",
    "Oscar = []\n",
    "meta_score = []\n",
    "mov_year = []\n",
    "casts = []\n",
    "mov_count = 0\n",
    "\n",
    "for imdb in imdb_url:\n",
    "    if imdb == None:\n",
    "        imdb_rating.append(None)\n",
    "        imdb_num_rating.append(None)\n",
    "        genres.append(None) \n",
    "        director.append(None)\n",
    "        Oscar.append(None)\n",
    "        meta_score.append(None)\n",
    "        mov_year.append(None)\n",
    "        casts.append(None)\n",
    "        continue\n",
    "    \n",
    "    fake = Factory.create()\n",
    "    header = {'User-Agent':fake.chrome()}\n",
    "    imdb_page = requests.get(imdb_page_base.format(imdb),headers = header)\n",
    "    imdb_p_soup = BeautifulSoup(imdb_page.text,'lxml')\n",
    "    \n",
    "    try:\n",
    "        #Get IMDB rating\n",
    "        imdb_rating.append(float(imdb_p_soup.find('div',class_='ratingValue').get_text().strip()[0:3]))\n",
    "    except Exception as e:\n",
    "        imdb_rating.append(None)\n",
    "    try:\n",
    "        #Number of IMDB ratings\n",
    "        imdb_num_rating.append(int(imdb_p_soup.find('span',itemprop='ratingCount').get_text().replace(',',\"\")))\n",
    "    except Exception as e:\n",
    "        imdb_num_rating.append(None)\n",
    "        \n",
    "    \n",
    "    try:\n",
    "    #Get all genres\n",
    "        imdb_genres = []\n",
    "        imdb_genre = imdb_p_soup.find_all('span',itemprop='genre')\n",
    "        for gen in imdb_genre:\n",
    "            imdb_genres.append(gen.get_text())\n",
    "            #print(imdb_genres)\n",
    "        genres.append(imdb_genres) \n",
    "    except Exception as e:\n",
    "        genres.setdefault(movie_names[mov_count], []).append(None)\n",
    "        \n",
    "    try:\n",
    "    #Get all genres\n",
    "        cast_members = []\n",
    "        cast_info = imdb_p_soup.find_all('span',itemprop='actors')\n",
    "        for cast in cast_info:\n",
    "            cast_members.append(cast.get_text().strip().replace(',',''))\n",
    "            #print(imdb_genres)\n",
    "        casts.append(cast_members)\n",
    "        movies_dict2[movie_names[mov_count]]=casts[mov_count]\n",
    "    except Exception as e:\n",
    "        #casts.setdefault(movie_names[mov_count], []).append(None)\n",
    "        casts.append(None)\n",
    "    try:\n",
    "        #Get director\n",
    "        director.append(imdb_p_soup.find('span',itemprop='director').get_text().strip())\n",
    "    except Exception as e:\n",
    "        director.append(None)\n",
    "    \n",
    "    try:    \n",
    "        #Get oscar\n",
    "        if (\"Won\" in imdb_p_soup.find('span',itemprop='awards').get_text().strip()) and (\"Oscar\" in imdb_p_soup.find('span',itemprop='awards').get_text().strip()):\n",
    "            Oscar.append('Yes')\n",
    "        else:\n",
    "            Oscar.append('No')\n",
    "    except Exception as e:\n",
    "        Oscar.append('No')\n",
    "    \n",
    "    try:\n",
    "        #Get the critics scores\n",
    "        meta_score.append(int(imdb_p_soup.find('div', class_='titleReviewBarSubItem').text.strip()))\n",
    "    except Exception as e:\n",
    "        meta_score.append(None)\n",
    "        \n",
    "    try:\n",
    "        #Get movie year\n",
    "        mov_year.append(int(re.sub(r'([^\\s\\w]|_)+', '',imdb_p_soup.find('span', id='titleYear').text.split()[0])))\n",
    "    except Exception as e:\n",
    "        mov_year.append(None)\n",
    "        \n",
    "    mov_count +=1\n",
    "    time.sleep(random.uniform(.02,.5)) #Put breaks into the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a dictionary from all of the list\n",
    "movie_data = {'mov_budget':budget,'mov_domestic':domestic,'mov_worldwide':worldwide,\n",
    "'mov_imdb_rating':imdb_rating,'mov_imdb_num':imdb_num_rating,'mov_genres':genres,\n",
    "'mov_director':director,'mov_oscar':Oscar,'meta_score':meta_score, 'mov_name':movie_names,'mov_year':mov_year}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a dataframe\n",
    "movie_df = pd.DataFrame(movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert the genres list into columns of dummy variables\n",
    "movie_df['mov_genres'].str.join(sep='*').str.get_dummies(sep='*')\n",
    "movie_df = pd.concat([movie_df, movie_df['mov_genres'].str.join(sep='*').str.get_dummies(sep='*')], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove movies with a budget of 0 and those that are older than 1960 because the inflation adjustment only goes back to 1960\n",
    "movie_df = movie_df[(movie_df['mov_domestic']!=0)]\n",
    "movie_df = movie_df[(movie_df['mov_year']>1960)] # will need to cut out movies older than 1960\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infl_domestic = []\n",
    "infl_worldwide = []\n",
    "infl_budget = []\n",
    "for row in range(0,4980):\n",
    "    try:\n",
    "        movie_df.loc[row,'infl_domestic'] = ep.normalize(amount=int(movie_df['mov_domestic'][row]), region=\"US\", from_year=int(join_movie_df['mov_year'][row]), to_year=\"latest\", base_currency=\"USD\")\n",
    "        movie_df.loc[row,'infl_worldwide'] = ep.normalize(amount=int(movie_df['mov_worldwide'][row]), region=\"US\", from_year=int(join_movie_df['mov_year'][row]), to_year=\"latest\", base_currency=\"USD\")\n",
    "        movie_df.loc[row,'infl_budget'] = ep.normalize(amount=int(movie_df['mov_budget'][row]), region=\"US\", from_year=int(join_movie_df['mov_year'][row]), to_year=\"latest\", base_currency=\"USD\")\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove any movies with NAs in these variables\n",
    "movie_df = movie_df[np.isfinite(movie_df['mov_imdb_rating'])]\n",
    "movie_df = movie_df[np.isfinite(movie_df['mov_year'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make dataframe into csv\n",
    "movie_df.to_csv('join_movie_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read movie and remove encoding\n",
    "movie_df = pd.read_csv('movie_df.csv',encoding = \"ISO-8859-1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
